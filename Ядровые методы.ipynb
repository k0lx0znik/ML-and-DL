{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RYp0bXOFK-hP"
      },
      "source": [
        "# Машинное обучение, ФКН ВШЭ\n",
        "\n",
        "## Практическое задание 8. Метод опорных векторов и аппроксимация ядер\n",
        "\n",
        "### Общая информация\n",
        "\n",
        "Дата выдачи: 30.01.2025\n",
        "\n",
        "Мягкий дедлайн: 23:59MSK 16.02.2025\n",
        "\n",
        "Жесткий дедлайн: 23:59MSK 23.02.2025\n",
        "\n",
        "### Оценивание и штрафы\n",
        "Каждая из задач имеет определенную «стоимость» (указана в скобках около задачи). Максимальная оценка за работу (без учёта бонусов) — 10 баллов.\n",
        "\n",
        "Сдавать задание после указанного жёсткого срока сдачи нельзя. При выставлении неполного балла за задание в связи с наличием ошибок на усмотрение проверяющего предусмотрена возможность исправить работу на указанных в ответном письме условиях.\n",
        "\n",
        "Задание выполняется самостоятельно. «Похожие» решения считаются плагиатом и все задействованные студенты (в том числе те, у кого списали) не могут получить за него больше 0 баллов (подробнее о плагиате см. на странице курса). Если вы нашли решение какого-то из заданий (или его часть) в открытом источнике, необходимо указать ссылку на этот источник в отдельном блоке в конце вашей работы (скорее всего вы будете не единственным, кто это нашел, поэтому чтобы исключить подозрение в плагиате, необходима ссылка на источник).\n",
        "\n",
        "Использование генеративных языковых моделей разрешено только в случае явного указания на это. Необходимо прописать (в соответствующих пунктах, где использовались, либо в начале/конце работы):\n",
        "- какая языковая модель использовалась\n",
        "- какие использовались промпты и в каких частях работы\n",
        "- с какими сложностями вы столкнулись при использовании генеративных моделей, с чем они помогли больше всего\n",
        "\n",
        "Неэффективная реализация кода может негативно отразиться на оценке.\n",
        "\n",
        "### Формат сдачи\n",
        "Задания сдаются через систему anytask. Посылка должна содержать:\n",
        "* Ноутбук homework-practice-08-random-features-Username.ipynb\n",
        "\n",
        "Username — ваша фамилия и имя на латинице именно в таком порядке"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vY8vT0W_K-hR"
      },
      "source": [
        "### О задании\n",
        "\n",
        "На занятиях мы подробно обсуждали метод опорных векторов (SVM). В базовой версии в нём нет чего-то особенного — мы всего лишь используем специальную функцию потерь, которая не требует устремлять отступы к бесконечности; ей достаточно, чтобы отступы были не меньше +1. Затем мы узнали, что SVM можно переписать в двойственном виде, который, позволяет заменить скалярные произведения объектов на ядра. Это будет соответствовать построению модели в новом пространстве более высокой размерности, координаты которого представляют собой нелинейные модификации исходных признаков.\n",
        "\n",
        "Ядровой SVM, к сожалению, довольно затратен по памяти (нужно хранить матрицу Грама размера $d \\times d$) и по времени (нужно решать задачу условной оптимизации с квадратичной функцией, а это не очень быстро). Мы обсуждали, что есть способы посчитать новые признаки $\\tilde \\varphi(x)$ на основе исходных так, что скалярные произведения этих новых $\\langle \\tilde \\varphi(x), \\tilde \\varphi(z) \\rangle$ приближают ядро $K(x, z)$.\n",
        "\n",
        "Мы будем исследовать аппроксимации методом Random Fourier Features (RFF, также в литературе встречается название Random Kitchen Sinks) для гауссовых ядер. Будем использовать формулы, которые немного отличаются от того, что было на лекциях (мы добавим сдвиги внутрь тригонометрических функций и будем использовать только косинусы, потому что с нужным сдвигом косинус превратится в синус):\n",
        "$$\\tilde \\varphi(x) = (\n",
        "\\cos (w_1^T x + b_1),\n",
        "\\dots,\n",
        "\\cos (w_n^T x + b_n)\n",
        "),$$\n",
        "где $w_j \\sim \\mathcal{N}(0, 1/\\sigma^2)$, $b_j \\sim U[-\\pi, \\pi]$.\n",
        "\n",
        "На новых признаках $\\tilde \\varphi(x)$ мы будем строить любую линейную модель.\n",
        "\n",
        "Можно считать, что это некоторая новая парадигма построения сложных моделей. Можно направленно искать сложные нелинейные закономерности в данных с помощью градиентного бустинга или нейронных сетей, а можно просто нагенерировать большое количество случайных нелинейных признаков и надеяться, что быстрая и простая модель (то есть линейная) сможет показать на них хорошее качество. В этом задании мы изучим, насколько работоспособна такая идея.\n",
        "\n",
        "### Алгоритм\n",
        "\n",
        "Вам потребуется реализовать следующий алгоритм:\n",
        "1. Понизить размерность выборки до new_dim с помощью метода главных компонент.\n",
        "2. Для полученной выборки оценить гиперпараметр $\\sigma^2$ с помощью эвристики (рекомендуем считать медиану не по всем парам объектов, а по случайному подмножеству из где-то миллиона пар объектов): $$\\sigma^2 = \\text{median}_{i, j = 1, \\dots, \\ell, i \\neq j} \\left\\{\\sum_{k = 1}^{d} (x_{ik} - x_{jk})^2 \\right\\}$$\n",
        "3. Сгенерировать n_features наборов весов $w_j$ и сдвигов $b_j$.\n",
        "4. Сформировать n_features новых признаков по формулам, приведённым выше.\n",
        "5. Обучить линейную модель (логистическую регрессию или SVM) на новых признаках.\n",
        "6. Повторить преобразования (PCA, формирование новых признаков) к тестовой выборке и применить модель."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fMPZ3vCx0f_J"
      },
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import time"
      ],
      "metadata": {
        "id": "4x2-5tCsLWjZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N_sGunb7K-hS"
      },
      "source": [
        "Тестировать алгоритм мы будем на данных Fashion MNIST. Ниже код для их загрузки и подготовки."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YyG6dBfjK-hS"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# 1 Способ\n",
        "import keras\n",
        "from keras.datasets import fashion_mnist\n",
        "(x_train_pics, y_train), (x_test_pics, y_test) = fashion_mnist.load_data()\n",
        "\n",
        "# 2 Способ (если первый не работает)\n",
        "# from sklearn.datasets import fetch_openml\n",
        "# def load_fashion_mnist():\n",
        "#     X, y = fetch_openml('Fashion-MNIST', version=1, return_X_y=True, as_frame=False)\n",
        "#     X = X.reshape(-1, 28, 28).astype('uint8')\n",
        "#     y = y.astype('int64')\n",
        "#     x_train, x_test = X[:60000], X[60000:]\n",
        "#     y_train, y_test = y[:60000], y[60000:]\n",
        "#     return (x_train, y_train), (x_test, y_test)\n",
        "# (x_train_pics, y_train), (x_test_pics, y_test) = load_fashion_mnist()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "x_train = x_train_pics.reshape(y_train.shape[0], -1)\n",
        "x_test = x_test_pics.reshape(y_test.shape[0], -1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "384le-_o0f_L"
      },
      "source": [
        "__Задание 0. (0.25 баллов)__\n",
        "\n",
        "**Вопрос:** зачем в алгоритме нужен метод главных компонент?\n",
        "\n",
        "**Ответ:** Если данные содержат много коррелированных или нерелевантных признаков, PCA помогает избавиться от них, тем самым помогает избавиться от переобучения."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rJNN55F7K-hT"
      },
      "source": [
        "__Задание 1. (3 балла)__\n",
        "\n",
        "Реализуйте алгоритм, описанный выше. Можете воспользоваться шаблоном класса в `homework_practice_08_rff.py` (допишите его и исправьте несостыковки в классе пайплайна) или написать свой интерфейс.\n",
        "\n",
        "Ваша реализация должна поддерживать следующие опции:\n",
        "1. Возможность задавать значения гиперпараметров new_dim (по умолчанию 50) и n_features (по умолчанию 1000).\n",
        "2. Возможность включать или выключать предварительное понижение размерности с помощью метода главных компонент.\n",
        "3. Возможность выбирать тип линейной модели (логистическая регрессия или SVM с линейным ядром).\n",
        "\n",
        "Протестируйте на данных Fashion MNIST, сформированных кодом выше. Если на тесте у вас получилась доля верных ответов не ниже 0.84 с гиперпараметрами по умолчанию, то вы всё сделали правильно."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jP8yepx8K-hT",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "from homework_practice_08_rff_SargsyanNarek import RFFPipeline, RandomFeatureCreator"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "pipeline = RFFPipeline(n_features=1000, new_dim=50, use_PCA=True, feature_creator_class=RandomFeatureCreator)\n",
        "\n",
        "start = time.time() #Начало времени обучения\n",
        "\n",
        "pipeline.fit(x_train, y_train)\n",
        "\n",
        "finish = time.time() # Окончение обучения\n",
        "\n",
        "startp = time.time() #Начало времени предсказания\n",
        "\n",
        "y_pred = pipeline.predict(x_test)\n",
        "\n",
        "finishp = time.time() # Окончение предсказания\n",
        "\n",
        "print(f\"Test score = {accuracy_score(y_test, y_pred)}, fit time {finish-start:.3} second, predict time {finishp-startp:.2} second\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0wBZQoBKx72y",
        "outputId": "c53b97de-f4dd-481c-930f-a0034e06e481"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test score = 0.8593, fit time 55.0 second, predict time 0.73 second\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HYqQUEi-K-hU"
      },
      "source": [
        "__Задание 2. (2.5 балла)__\n",
        "\n",
        "Сравните подход со случайными признаками с обучением SVM на исходных признаках. Попробуйте вариант с обычным (линейным) SVM и с ядровым SVM. Ядровой SVM может очень долго обучаться, поэтому можно делать любые разумные вещи для ускорения: брать подмножество объектов из обучающей выборки, например.\n",
        "\n",
        "Сравните подход со случайными признаками с вариантом, в котором вы понижаете размерность с помощью PCA и обучите градиентный бустинг. Используйте одну из реализаций CatBoost/LightGBM/XGBoost.\n",
        "\n",
        "Сделайте выводы — насколько идея со случайными признаками работает? Сравните как с точки зрения качества, так и с точки зрения скорости обучения и применения."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Начнем сперва с SVM"
      ],
      "metadata": {
        "id": "OTjVlLmIPtLH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qN8LUlJgK-hV"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVC"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Сперва попробуем линейный SVM"
      ],
      "metadata": {
        "id": "veZSBM3wP63p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Возьмем часть выборки\n",
        "np.random.seed(152)\n",
        "indices_train = np.random.choice(x_train.shape[0], size=(x_train.shape[0] // 8), replace=False)\n",
        "indices_test = np.random.choice(x_test.shape[0], size=(x_test.shape[0] // 8), replace=False)\n",
        "\n",
        "x_train_sample = x_train[indices_train]\n",
        "x_test_sample = x_test[indices_test]\n",
        "y_train_sample = y_train[indices_train]\n",
        "y_test_sample = y_test[indices_test]"
      ],
      "metadata": {
        "id": "8m9Dz9mHRZyJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "svm_lin = SVC(kernel='linear')\n",
        "start = time.time() #Начало времени обучения\n",
        "\n",
        "svm_lin.fit(x_train_sample, y_train_sample)\n",
        "\n",
        "finish = time.time() # Окончение обучения\n",
        "\n",
        "startp = time.time() #Начало времени предсказания\n",
        "\n",
        "y_pred = svm_lin.predict(x_test_sample)\n",
        "\n",
        "finishp = time.time() # Окончение предсказания\n",
        "\n",
        "print(f'Test score for linear SVM = {accuracy_score(y_test_sample, y_pred)}, fit time {finish-start:.2} second, predict time {finishp-startp:.2} second')"
      ],
      "metadata": {
        "id": "tEFdAi-uvnUV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6f5c2fe-08d5-42d8-97bc-004b3a6a083a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test score for linear SVM = 0.784, fit time 7.7 second, predict time 1.9 second\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Теперь ядровой SVM"
      ],
      "metadata": {
        "id": "ZCKyAogDYKcH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "svm_rbf = SVC(kernel='rbf')\n",
        "\n",
        "start = time.time() #Начало времени обучения\n",
        "\n",
        "svm_rbf.fit(x_train_sample, y_train_sample)\n",
        "\n",
        "finish = time.time() # Окончение обучения\n",
        "\n",
        "startp = time.time() #Начало времени предсказания\n",
        "\n",
        "y_pred = svm_rbf.predict(x_test_sample)\n",
        "\n",
        "finishp = time.time() # Окончение предсказания\n",
        "\n",
        "print(f'Test score for RBF SVM = {accuracy_score(y_test_sample, y_pred)}, fit time {finish-start:.2} second, predict time {finishp-startp:.2} second')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HDkaouO-ZHMa",
        "outputId": "f4ca9892-f5c0-4452-e60e-d005f755e685"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test score for RBF SVM = 0.8312, fit time 6.0 second, predict time 3.6 second\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Теперь используем GB"
      ],
      "metadata": {
        "id": "5gNbfRofclC6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install catboost"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BQD1wspqernF",
        "outputId": "881537af-2923-4d5e-af44-8c51d02ec598"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: catboost in /usr/local/lib/python3.11/dist-packages (1.2.7)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.11/dist-packages (from catboost) (0.20.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from catboost) (3.10.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.11/dist-packages (from catboost) (1.26.4)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.11/dist-packages (from catboost) (2.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from catboost) (1.13.1)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.11/dist-packages (from catboost) (5.24.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from catboost) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2025.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (3.2.1)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly->catboost) (9.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from catboost import CatBoostClassifier"
      ],
      "metadata": {
        "id": "t1ZR5j5Ve6xE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Гиперпараметры я не буду подбирать, так как это долго."
      ],
      "metadata": {
        "id": "3mQ26AqVe-MG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cb_clf = CatBoostClassifier(verbose=False, n_estimators=500, max_depth=6, min_child_samples=5, learning_rate=0.7)\n",
        "\n",
        "start = time.time() #Начало времени обучения\n",
        "\n",
        "cb_clf.fit(x_train_sample, y_train_sample)\n",
        "\n",
        "finish = time.time() # Окончение обучения\n",
        "\n",
        "startp = time.time() #Начало времени предсказания\n",
        "\n",
        "y_pred = cb_clf.predict(x_test_sample)\n",
        "\n",
        "finishp = time.time() # Окончение предсказания\n",
        "\n",
        "print(f'Test score of Catboost = {accuracy_score(y_test_sample, y_pred)},fit time {finish-start:.2} second, predict time {finishp-startp:.2} second')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BcwDQcrRfFfE",
        "outputId": "3e60d6f4-516e-400d-ec8b-cd2a4aaff0e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test score of Catboost = 0.8456,fit time 9.6e+02 second, predict time 0.62 second\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Подведем итогы:\n",
        "\n",
        "1) Лучше всех оказалась логистическая регрессия с RFF, так как он имеет более высокое accuracy (около 0.85), по скоростьи он на 3 метсе, обучался около 50 секунд.\n",
        "\n",
        "2) На втором месте Catboost с accuracy 0.84, но обучение самое долгое, около 15 минут, несмотря на то, что обучался на 12% выборки.\n",
        "\n",
        "3) Потом по точности лучшее всех ядровой SVM, около 0.84. По скорости обучения занимает 1 место, аж 6 секунд, но на части данных.\n",
        "\n",
        "4) Хуже всех по accuracy оказался обычный линейный svm, около 0.77, но по скорости быстрее всех - 7 секунд (тоже на части данных).\n",
        "\n",
        "Скорости предсказания: \\\\\n",
        "1) На первом месте ГБ аж 0.6 секунд \\\\\n",
        "2) Логистическая регрессия с RFF 0.7 секнуд \\\\\n",
        "3) Линейный SVM 2 секунда \\\\\n",
        "4) Ядровой SVM 3 секунды\n",
        "\n",
        "SVM-ы без урезанной выборки обучались дольше 3-5 миниут, и тем самым уже проигрывают логрегу с RFF. Поэтому оставил урезанную, чтобы при частом запуске не ждать долго.\n"
      ],
      "metadata": {
        "id": "5k0it4uGv8kB"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e6umjhWuK-hV"
      },
      "source": [
        "__Задание 3. (2 балла)__\n",
        "\n",
        "Проведите эксперименты:\n",
        "1. Помогает ли предварительное понижение размерности с помощью PCA?\n",
        "2. Как зависит итоговое качество от n_features? Выходит ли оно на плато при росте n_features?\n",
        "3. Важно ли, какую модель обучать — логистическую регрессию или SVM?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Начнем с первого пункта"
      ],
      "metadata": {
        "id": "IuQkiS2-mjpe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c2QIHIMbK-hW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f94b2aff-aaa1-4443-ad72-2f2fb36bd12c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test score on RFF without PCA = 0.1089\n"
          ]
        }
      ],
      "source": [
        "pipeline_without_pca = RFFPipeline(n_features=1000, new_dim=50, use_PCA=False, feature_creator_class=RandomFeatureCreator)\n",
        "\n",
        "pipeline_without_pca.fit(x_train, y_train)\n",
        "\n",
        "y_pred = pipeline_without_pca.predict(x_test)\n",
        "print(f'Test score on RFF without PCA = {accuracy_score(y_test, y_pred)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Как мы видим без PCA accuracy упал 8 раз. То есть PCA помогает нам, он необхадим."
      ],
      "metadata": {
        "id": "aCSyUAoTomlG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Второй пункт"
      ],
      "metadata": {
        "id": "-DPtufGvo_e2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline_new = RFFPipeline(n_features=200, new_dim=50, use_PCA=True, feature_creator_class=RandomFeatureCreator) #Уменьшим c 1000 до 200 n_feature\n",
        "\n",
        "pipeline_new.fit(x_train, y_train)\n",
        "\n",
        "y_pred = pipeline_new.predict(x_test)\n",
        "print(f'Test score on RFF with 200 n_feature = {accuracy_score(y_test, y_pred)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E5U50GXdo1Tp",
        "outputId": "69413020-c333-4003-fe37-931729ec51fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test score on RFF with 200 n_feature = 0.8454\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "C уменьшем n_feature accuracy падает, теперь попробуем увеличить"
      ],
      "metadata": {
        "id": "fXMiPwlWqNh9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline_new = RFFPipeline(n_features=2000, new_dim=50, use_PCA=True, feature_creator_class=RandomFeatureCreator) #Увелечививаем c 1000 до 2000 n_feature\n",
        "\n",
        "pipeline_new.fit(x_train, y_train)\n",
        "\n",
        "y_pred = pipeline_new.predict(x_test)\n",
        "print(f'Test score on RFF with 2000 n_feature = {accuracy_score(y_test, y_pred)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K1u5WUd5qeX9",
        "outputId": "f4bd0184-35ae-4a33-c3b1-3a46e9ddaba8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test score on RFF with 2000 n_feature = 0.8609\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline_new = RFFPipeline(n_features=4000, new_dim=50, use_PCA=True, feature_creator_class=RandomFeatureCreator) #Увелечививаем c 2000 до 4000 n_feature\n",
        "\n",
        "pipeline_new.fit(x_train, y_train)\n",
        "\n",
        "y_pred = pipeline_new.predict(x_test)\n",
        "print(f'Test score on RFF with 4000 n_feature = {accuracy_score(y_test, y_pred)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Jnhm-1nq4pg",
        "outputId": "5a7a2b72-633e-4ed9-eb43-9ba3f9fbdd11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test score on RFF with 4000 n_feature = 0.861\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Как видим, с увеличением растет accuracy, но выходит на плато, поэтому n_feature должно быть большим, но не сильно"
      ],
      "metadata": {
        "id": "xT8YYrmMsRmZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Третий пункт\n",
        "\n",
        "Попробуем линейным SVM"
      ],
      "metadata": {
        "id": "xSdww0h4socq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline_svm = RFFPipeline(n_features=1000, new_dim=50, use_PCA=True, feature_creator_class=RandomFeatureCreator, classifier_class=SVC, classifier_params={'kernel': 'linear'})\n",
        "\n",
        "start = time.time() #Начало времени обучения\n",
        "\n",
        "pipeline_svm.fit(x_train, y_train)\n",
        "\n",
        "finish = time.time() #Конец времени обучения\n",
        "\n",
        "startp = time.time() #Начало времени предсказания\n",
        "\n",
        "y_pred = pipeline_svm.predict(x_test)\n",
        "\n",
        "finishp = time.time() # Окончение предсказания\n",
        "\n",
        "print(f'Test score on RFF with linear SVM = {accuracy_score(y_test, y_pred)}, fit time {finish-start:.2} second, predict time {finishp-startp:.2} second')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hzReC-8usqET",
        "outputId": "5748f6a8-dbf1-4ef5-bb16-4004e33ba596"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test score on RFF with linear SVM = 0.8796, fit time 5.3e+02 second, predict time 1.1e+02 second\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "По части качества SVM c RFF гораздо лучше, чем логрег с RFF, но по части скорости обучения и предсказания в 10 раз уступает логрегу."
      ],
      "metadata": {
        "id": "IaK31dFqMWmn"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4pc7-1jmK-hY"
      },
      "source": [
        "__Задание 5. (Максимум 1 балл)__\n",
        "\n",
        "Существует большое количество работ, где идея RFF развивается, предлагаются её обобщения (которые, по сути, выливаются в другие преобразования признаков, не обязательно уже тригонометрические). Возьмите любую из таких работ, кратко опишите идею, имплементируйте её и сравните качество с ORF и RFF, которые вы запрограммировали выше.\n",
        "\n",
        "Ссылки на статьи, где обсуждаются вариации RFF для разных ядер, можно найти в окрестности таблицы 1 в работе https://arxiv.org/pdf/1407.5599"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Я решил рассматреть полиномиальное ядро\n",
        "\n",
        "___ссылка на работу:___ https://arxiv.org/pdf/2212.07658\n",
        "\n",
        "___описание идеи:___ Основная идея заключается в том, что если данные не разделяются линейно в исходном пространстве, то с помощью полиномиального ядра их можно перенести в пространство более высокой размерности, где разделение становится возможным.\n",
        "\n",
        "Ядро выглядит следующим образом\n",
        "\n",
        "$$\n",
        "K(x,z) = (x^{T}z + c)^{d}\n",
        "$$\n",
        "\n",
        "где *с* и *d* являются гиперпараметрами.\n",
        "\n",
        "Он уже релизован в sklearn, поэтому сразу можно использовать его."
      ],
      "metadata": {
        "id": "saAYlcT_7YIx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dWj-O2vjK-hY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c37e05c-2b2c-4072-885a-7e66527e3ebe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test score on SVM with poly kernel = 0.8875, fit time 3.2e+02 second, predict time 1.1e+02 second\n"
          ]
        }
      ],
      "source": [
        "svc_poly = SVC(kernel='poly', degree = 3, coef0=0.5)\n",
        "\n",
        "start = time.time() #Начало времени обучения\n",
        "\n",
        "svc_poly.fit(x_train, y_train)\n",
        "\n",
        "finish = time.time() #Конец времени обучения\n",
        "\n",
        "startp = time.time() #Начало времени предсказания\n",
        "\n",
        "y_pred = svc_poly.predict(x_test)\n",
        "\n",
        "finishp = time.time() # Окончение предсказания\n",
        "\n",
        "print(f'Test score on SVM with poly kernel = {accuracy_score(y_test, y_pred)}, fit time {finish-start:.2} second, predict time {finishp-startp:.2} second')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "По результату SVM c полиномиальным ядром лучше чем логрег и linear SVM с RFF. По скорости он явно медленее логрега с RFF, но быстрее SVM-a (который тоже с RFF). Обучился за 5 минут, а предсказивал за 2 минуты."
      ],
      "metadata": {
        "id": "kp67OASA_T1s"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iqLKHkvj0f_M"
      },
      "source": [
        "__Задание 6. (Максимум 2.5 балла)__\n",
        "\n",
        "Реализуйте класс ядровой Ridge регрессии (Лекция 13, $\\S 1.2$), для оптимизации используте градиентный спуск **[1 балл максимум]**, также добавьте возможность использовать аналитическую формулу **[1 балл максимум]**. Для градиентного спуска выпишите градиент ниже **[0.5 баллов максимум]**.\n",
        "Подумайте о том, как в формулах правильно учесть свободный коэффициент.\n",
        "\n",
        "Затем адаптируйте вашу реализацию RFF под задачу регрессии. Сравните вашу ядровую регрессию и RFF на синтетических данных."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sfnYGjfv0f_M"
      },
      "source": [
        "Функция потерь:\n",
        "$$\n",
        "Q(w) = \\frac{1}{2} ||\\Phi \\Phi^T w - y||^2 + \\frac{\\lambda}{2} w^T \\Phi \\Phi^T w \\rightarrow \\min_w,\n",
        "$$\n",
        "где $\\Phi \\Phi^T = K$, $K = (k(x_i, x_j))_{i, j = 1}^{\\ell}$.\n",
        "\n",
        "Предсказание:\n",
        "$\n",
        "y(x) = k(x)^T w,\n",
        "$\n",
        "где $k(x)$ — вектор функций ядра от пар объектов $(x, x_i)_{i=1}^{\\ell}$.\n",
        "\n",
        "___Выведите градиент:___\n",
        "$$\n",
        "\\nabla_{w}Q(w) = \\Phi\\Phi^{T}(\\Phi\\Phi^{T}w-y) + \\lambda  \\Phi\\Phi^{T}w\n",
        "$$\n",
        "\n",
        "Вы можете изменять представленный шаблон в файле `homework_practice_08_kernel_regression.py` по своему усмотрению."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Я сразу же написал $$ \\Phi\\Phi^{T} $$ так как матрица симметричная и\n",
        "\n",
        "$$\n",
        "\\Phi\\Phi^{T} = (\\Phi\\Phi^{T})^{T}\n",
        "$$"
      ],
      "metadata": {
        "id": "pzsNO0j2HoEy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y7ePjpdt0f_M"
      },
      "outputs": [],
      "source": [
        "from homework_practice_08_kernel_regression_SargsyanNarek import KernelRidgeRegression"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import r2_score"
      ],
      "metadata": {
        "id": "ji20IaoVBBcI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Начнем с синтетических данных"
      ],
      "metadata": {
        "id": "2mGsnQSaMZ6H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lin_reg = KernelRidgeRegression(regularization=10, lr = 0.004, max_iter=500, batch_size=64, kernel_scale = 18)"
      ],
      "metadata": {
        "id": "vHPQ9lYO4rv8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import make_regression\n",
        "np.random.seed(152)\n",
        "X, y = make_regression(n_samples=1500, n_features=15)\n",
        "\n",
        "# Шаг 2: Разделение данных на train и test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=153)"
      ],
      "metadata": {
        "id": "r2Ce4cTD0yne"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lin_reg.fit_closed_form(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s0xBy6C701CC",
        "outputId": "bbeb4909-d695-43b7-a8ac-962b9ba88df0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<homework_practice_08_kernel_regression_SargsyanNarek.KernelRidgeRegression at 0x78f5f1b4ff10>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred = lin_reg.predict(X_test)"
      ],
      "metadata": {
        "id": "_mj8zwBX07Dq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'MSE on train {mean_squared_error(y_train, lin_reg.predict(X_train))}')\n",
        "print(f'R2 on train {r2_score(y_train, lin_reg.predict(X_train))}')\n",
        "print(f'MSE on test {mean_squared_error(y_test, pred)}')\n",
        "print(f'R2 on test {r2_score(y_test, pred)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q2aoETBR13Bu",
        "outputId": "fcf02bcc-a684-498d-e08f-498eede44b07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE on train 3.55412493114913\n",
            "R2 on train 0.9998865378274284\n",
            "MSE on test 3.5571434584369257\n",
            "R2 on test 0.9998940928767662\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Если обучать дефолтными переметрами, то там будет жуткое переобучение, поэтому важно подобрать гиперпараметры. Также важно отметить, что обучается около 40 секунд.\n",
        "\n",
        "\n",
        "Попробуем теперь линрег с градиентным спуском"
      ],
      "metadata": {
        "id": "B02A4JqszBVx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "d1-1NTqHBfyl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lin_reg = KernelRidgeRegression(regularization=4, lr = 0.004, max_iter=20000, batch_size=64, kernel_scale = 5)"
      ],
      "metadata": {
        "id": "ML9yl4k1SCNq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lin_reg.fit(X_train, y_train)\n",
        "pred = lin_reg.predict(X_test)"
      ],
      "metadata": {
        "id": "H7DDqalN4H3s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'MSE on train {mean_squared_error(y_train, lin_reg.predict(X_train))}')\n",
        "print(f'R2 on train {r2_score(y_train, lin_reg.predict(X_train))}')\n",
        "print(f'MSE on test {mean_squared_error(y_test, pred)}')\n",
        "print(f'R2 on test {r2_score(y_test, pred)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lHtvOLhW4Nza",
        "outputId": "6055d3c3-7557-4934-cbf2-38fb16626c67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE on train 2266.8708377156668\n",
            "R2 on train 0.9276322315143873\n",
            "MSE on test 2950.4674939092383\n",
            "R2 on test 0.9121554898963571\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Он как то очень медленно идет к миниммуму, но в целом работает. Какой нибудь шкедулер или другой метод градиентного спуска дали бы лучше результат."
      ],
      "metadata": {
        "id": "MjKtuCzI582G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Теперь сгенерируем датасет и спользуем логрег с RFF"
      ],
      "metadata": {
        "id": "lvybS3UoMebD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "np.random.seed(152)\n",
        "\n",
        "X_linear, y_linear = make_classification(n_samples=1500, n_features=17, n_classes=2,\n",
        "                                         n_informative=2, n_redundant=0, random_state=42)\n",
        "\n",
        "X_train_lin, X_test_lin, y_train_lin, y_test_lin = train_test_split(X_linear, y_linear, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "Rsh72RmmMhbM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipe_syn = RFFPipeline(n_features=10).fit(X_train_lin, y_train_lin)\n",
        "\n",
        "y_pred = pipe_syn.predict(X_test_lin)\n",
        "\n",
        "print(f\"Train score = {accuracy_score(y_train_lin, pipe_syn.predict(X_train_lin)):.2}\")\n",
        "print(f\"Test score = {accuracy_score(y_test_lin, y_pred):.2}\")"
      ],
      "metadata": {
        "id": "8uAiyHm6Mvxd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d658d90-b0a5-455d-d019-d8ddf0c5559d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train score = 0.89\n",
            "Test score = 0.87\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "С задачей классификации никаких проблем нет, все отлично предсказывает."
      ],
      "metadata": {
        "id": "qlhc8cqG3a7V"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}